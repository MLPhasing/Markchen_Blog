<!DOCTYPE html>
<head>
  <meta charset="UTF-8">
  	<title>{{ site.title }}</title>
  	<meta name="viewport" content="width=device-width, initial-scale=1">
  	<meta name="theme-color" content="#157878">
  	<link rel="stylesheet" href="https://markchenyutian.github.io/Markchen_Blog/css/normalize.css">
  	<link rel="stylesheet" href="https://markchenyutian.github.io/Markchen_Blog/css/main_.css">
  	<link rel="stylesheet" href="https://markchenyutian.github.io/Markchen_Blog/css/sidebar.css">
	<link rel="stylesheet" type="text/css" href="Asset/css/Unified_Style.css">
</head>

<body>
	
	<section class="page-header">
	  <h1 class="project-name">Mark's Blog</h1>
	  <a href="https://github.com/MarkChenYutian/Markchen_Blog" class="btn">View on GitHub</a>
	  <a href="https://markchenyutian.github.io/Markchen_Blog/" class="btn">Back to Homepage</a>
	  <a href="https://markchenyutian.github.io/Markchen_Blog/2020/10/04/Index.html" class="btn">All Posts</a>
	</section>
	
	<section class="side_bar">
		
	</section>
	
	<section class="main-content">

		<div>
			
			<h2>Neural Network</h2>
			
			<div class="card">
				<div class="title_container">
					<h4>Residual Network</h4>
				</div>
				<div class="container">
					Before the Residual Network, People are not able to train a neural network with more than 50 layers. Due to the fundamental problem of gradient vanish and explosion, the accuaracy of model with too many layers is extremely unstable. Although more convolutional layers in the model means that the model will be able to extract more complicated features, the actual performance of deep network is usually worse. With shortcut connection between convolutional layers, ResNet with 1000+ layers can be trained without obvious degredation.
				</div>
			</div>
			
			<div style="height:10px"></div>
			
			<div class="card">
				<div class="title_container">
					<h4>Long-short Term Memory (LSTM) Network</h4>
				</div>
				<div class="container">
					Usually, convolutional network can only take in one input at a time and treat each input seperately. In order to utilize the information from context, people proposed the Recurrent Neural Network (RNN), where the hidden state will be delivered between network in different time. However, the simple structure of RNN will lead to gradient vanish and explosion in some situation, and it can't deal with the long context. To solve this problem, the LSTM is proposed, where cell state and hidden state is delivered between network.
				</div>
			</div>
			
		</div>

		<footer class="site-footer">
		  <span class="site-footer-owner"><a href="https://markchenyutian.github.io/Markchen_Blog">Mark's Blog</a> is maintained by Yutian Chen markchenyutian@gmail.com</span>
		  <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
		</footer>
	</section>

</body>